import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba
import time

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .stApp { max-width: 1200px; margin: 0 auto; }
    .highlight-conflict { background-color: #ffeeba; padding: 2px 4px; border-radius: 3px; }
    .clause-box { border-left: 4px solid #007bff; padding: 10px; margin: 10px 0; background-color: #f8f9fa; }
    .model-response { background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin: 10px 0; }
    .section-header { background-color: #f8f9fa; padding: 10px; border-radius: 5px; margin: 15px 0; }
</style>
""", unsafe_allow_html=True)

# é…ç½®Qwen APIå‚æ•°
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

def call_qwen_api(prompt, api_key, retry=2):
    """è°ƒç”¨Qwenå¤§æ¨¡å‹APIï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    if not api_key:
        st.error("Qwen APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨å·¦ä¾§æ è¾“å…¥å¯†é’¥")
        return None
        
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": "qwen-plus",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
            "max_tokens": 1000
        }
        
        # å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨
        for attempt in range(retry):
            try:
                response = requests.post(
                    QWEN_API_URL,
                    headers=headers,
                    json=data,
                    timeout=60
                )
                
                if response.status_code == 200:
                    response_json = response.json()
                    if "choices" in response_json and len(response_json["choices"]) > 0:
                        return response_json["choices"][0]["message"]["content"]
                time.sleep(2 **attempt)  # æŒ‡æ•°é€€é¿
                
            except Exception as e:
                if attempt == retry - 1:
                    st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
                
        return None
        
    except Exception as e:
        st.error(f"è°ƒç”¨Qwen APIå¤±è´¥: {str(e)}")
        return None

def extract_text_from_pdf(file, progress_bar=None):
    """ä»PDFæå–æ–‡æœ¬"""
    try:
        pdf_reader = PdfReader(file)
        text = ""
        total_pages = len(pdf_reader.pages)
        
        for i, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text() or ""
            # å¤„ç†ä¸­æ–‡ç©ºæ ¼å’Œæ¢è¡Œé—®é¢˜
            page_text = page_text.replace("  ", "").replace("\n", "").replace("\r", "")
            text += page_text
            
            # æ›´æ–°è¿›åº¦æ¡
            if progress_bar is not None:
                progress = (i + 1) / total_pages
                progress_bar.progress(progress)
        
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""

def split_into_clauses(text, doc_name="æ–‡æ¡£"):
    """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ¡æ¬¾ï¼Œç®€åŒ–ç‰ˆ"""
    # ç®€åŒ–çš„æ¡æ¬¾åˆ†å‰²æ¨¡å¼
    patterns = [
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s*[:ï¼š]?\s*.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s*[:ï¼š]?\s*|$)',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*|$)',
        r'(\d+\.\s*.*?)(?=\d+\.\s*|$)',
    ]
    
    # å°è¯•å„ç§æ¨¡å¼ï¼Œæ‰¾åˆ°æœ€ä½³åˆ†å‰²
    best_clauses = []
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        # è¿‡æ»¤è¿‡çŸ­æ¡æ¬¾
        clauses = [clause.strip() for clause in clauses if clause.strip() and len(clause.strip()) > 10]
        if len(clauses) > len(best_clauses) and len(clauses) > 2:
            best_clauses = clauses
    
    # å¦‚æœæ‰¾åˆ°è¶³å¤Ÿçš„æ¡æ¬¾ï¼Œè¿”å›ç»“æœ
    if best_clauses:
        return best_clauses
    
    # å°è¯•æ®µè½åˆ†å‰²ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    return [p.strip() for p in paragraphs if p.strip() and len(p) > 10]

def chinese_text_similarity(text1, text2):
    """è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦ï¼Œç®€åŒ–ç‰ˆ"""
    # è¿‡æ»¤æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
    text1_clean = re.sub(r'[^\w\s]', '', text1)
    text2_clean = re.sub(r'[^\w\s]', '', text2)
    
    # ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
    words1 = list(jieba.cut(text1_clean))
    words2 = list(jieba.cut(text2_clean))
    
    # è®¡ç®—åˆ†è¯åçš„ç›¸ä¼¼åº¦
    return SequenceMatcher(None, words1, words2).ratio()

def match_clauses(clauses1, clauses2, progress_container=None):
    """åŒ¹é…ä¸¤ä¸ªæ–‡æ¡£ä¸­çš„ç›¸ä¼¼æ¡æ¬¾ï¼Œç®€åŒ–ç‰ˆåŒ¹é…ç®—æ³•"""
    matched_pairs = []
    used_indices = set()
    total = len(clauses1)
    
    for i, clause1 in enumerate(clauses1):
        # æ›´æ–°è¿›åº¦
        if progress_container is not None:
            progress = (i + 1) / total
            with progress_container:
                st.progress(progress)
        
        best_match = None
        best_ratio = 0.25  # åŸºç¡€é˜ˆå€¼
        best_j = -1
        
        # åªæ£€æŸ¥æœªåŒ¹é…çš„æ¡æ¬¾
        candidates = [j for j in range(len(clauses2)) if j not in used_indices]
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        for j in candidates:
            ratio = chinese_text_similarity(clause1, clauses2[j])
            if ratio > best_ratio:
                best_ratio = ratio
                best_match = clauses2[j]
                best_j = j
        
        if best_match:
            matched_pairs.append((clause1, best_match, best_ratio))
            used_indices.add(best_j)
    
    # å¤„ç†æœªåŒ¹é…çš„æ¡æ¬¾
    unmatched1 = [clause for i, clause in enumerate(clauses1) 
                 if i not in [idx for idx, _ in enumerate(matched_pairs)]]
    unmatched2 = [clause for j, clause in enumerate(clauses2) if j not in used_indices]
    
    return matched_pairs, unmatched1, unmatched2

def create_download_link(content, filename, text):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    b64 = base64.b64encode(content.encode()).decode()
    return f'<a href="data:file/txt;base64,{b64}" download="{filename}">{text}</a>'

def analyze_compliance_with_qwen(clause1, clause2, filename1, filename2, api_key):
    """ä½¿ç”¨Qwenå¤§æ¨¡å‹åˆ†ææ¡æ¬¾åˆè§„æ€§ï¼Œç®€åŒ–æç¤ºè¯"""
    prompt = f"""
    è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªæ¡æ¬¾æ˜¯å¦å­˜åœ¨å†²çªï¼š
    
    {filename1} æ¡æ¬¾ï¼š{clause1}
    {filename2} æ¡æ¬¾ï¼š{clause2}
    
    è¯·ç”¨ä¸­æ–‡ç®€è¦åˆ†æï¼š
    1. ç›¸ä¼¼åº¦è¯„ä¼°ï¼ˆé«˜/ä¸­/ä½ï¼‰
    2. ä¸»è¦å·®å¼‚ç‚¹
    3. åˆè§„æ€§åˆ¤æ–­ï¼ˆæ— å†²çª/è½»å¾®å†²çª/ä¸¥é‡å†²çªï¼‰
    4. ç®€è¦å»ºè®®
    """
    
    return call_qwen_api(prompt, api_key)

def analyze_single_comparison(base_clauses, compare_text, base_name, compare_name, api_key):
    """åˆ†æå•ä¸ªå¯¹æ¯”æ–‡ä»¶ä¸åŸºå‡†æ–‡ä»¶çš„åˆè§„æ€§ï¼Œç®€åŒ–ç‰ˆ"""
    # åˆ†å‰²å¯¹æ¯”æ–‡ä»¶æ¡æ¬¾
    with st.spinner(f"æ­£åœ¨åˆ†æ {compare_name} çš„æ¡æ¬¾..."):
        compare_clauses = split_into_clauses(compare_text, compare_name)
        st.success(f"{compare_name} è¯†åˆ«å‡º {len(compare_clauses)} æ¡æ¡æ¬¾")
    
    # åŒ¹é…æ¡æ¬¾ï¼Œæ˜¾ç¤ºè¿›åº¦
    progress_container = st.empty()
    with st.spinner(f"æ­£åœ¨åŒ¹é…æ¡æ¬¾..."):
        matched_pairs, unmatched_base, unmatched_compare = match_clauses(
            base_clauses, 
            compare_clauses,
            progress_container
        )
    progress_container.empty()
    
    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    st.divider()
    col1, col2, col3 = st.columns(3)
    col1.metric(f"{base_name} æ¡æ¬¾æ•°", len(base_clauses))
    col2.metric(f"{compare_name} æ¡æ¬¾æ•°", len(compare_clauses))
    col3.metric("åŒ¹é…æ¡æ¬¾æ•°", len(matched_pairs))
    
    # æ˜¾ç¤ºæ¡æ¬¾å¯¹æ¯”å’Œåˆè§„æ€§åˆ†æ
    st.divider()
    st.subheader(f"æ¡æ¬¾åˆè§„æ€§åˆ†æ")
    
    # åˆ›å»ºåˆ†æç»“æœçš„æ ‡ç­¾é¡µå¯¼èˆª
    tab_labels = ["åŒ¹é…æ¡æ¬¾"]
    if len(unmatched_base) > 0:
        tab_labels.append(f"{base_name} ç‹¬æœ‰æ¡æ¬¾")
    if len(unmatched_compare) > 0:
        tab_labels.append(f"{compare_name} ç‹¬æœ‰æ¡æ¬¾")
    
    tabs = st.tabs(tab_labels)
    tab_idx = 0
    
    # åˆ†ææ¯ä¸ªåŒ¹é…å¯¹çš„åˆè§„æ€§
    with tabs[tab_idx]:
        tab_idx += 1
        
        # æ·»åŠ ç­›é€‰åŠŸèƒ½
        min_similarity = st.slider("æœ€ä½ç›¸ä¼¼åº¦ç­›é€‰", 0.0, 1.0, 0.0, 0.05)
        filtered_pairs = [p for p in matched_pairs if p[2] >= min_similarity]
        
        st.write(f"æ˜¾ç¤º {len(filtered_pairs)} ä¸ªåŒ¹é…é¡¹")
        
        for i, (clause1, clause2, ratio) in enumerate(filtered_pairs):
            # æ ¹æ®ç›¸ä¼¼åº¦è®¾ç½®ä¸åŒé¢œè‰²æ ‡è¯†
            if ratio > 0.7:
                similarity_color = "#28a745"  # ç»¿è‰² - é«˜ç›¸ä¼¼åº¦
                similarity_label = "é«˜ç›¸ä¼¼åº¦"
            elif ratio > 0.4:
                similarity_color = "#ffc107"  # é»„è‰² - ä¸­ç›¸ä¼¼åº¦
                similarity_label = "ä¸­ç›¸ä¼¼åº¦"
            else:
                similarity_color = "#dc3545"  # çº¢è‰² - ä½ç›¸ä¼¼åº¦
                similarity_label = "ä½ç›¸ä¼¼åº¦"
            
            st.markdown(f"### åŒ¹é…æ¡æ¬¾å¯¹ {i+1}")
            st.markdown(f'<span style="color:{similarity_color};font-weight:bold">{similarity_label}: {ratio:.2%}</span>', unsafe_allow_html=True)
            
            col_a, col_b = st.columns(2)
            with col_a:
                st.markdown(f'<div class="clause-box"><strong>{base_name} æ¡æ¬¾:</strong><br>{clause1}</div>', unsafe_allow_html=True)
            with col_b:
                st.markdown(f'<div class="clause-box"><strong>{compare_name} æ¡æ¬¾:</strong><br>{clause2}</div>', unsafe_allow_html=True)
            
            # æ·»åŠ åˆ†æç»“æœæŠ˜å æ¡†
            with st.expander("æŸ¥çœ‹åˆè§„æ€§åˆ†æ", expanded=False):
                with st.spinner("æ­£åœ¨åˆ†æ..."):
                    analysis = analyze_compliance_with_qwen(clause1, clause2, base_name, compare_name, api_key)
                
                if analysis:
                    st.markdown('<div class="model-response">' + analysis + '</div>', unsafe_allow_html=True)
                else:
                    st.warning("æœªèƒ½è·å–åˆ†æç»“æœ")
            
            st.divider()
    
    # æœªåŒ¹é…çš„æ¡æ¬¾åˆ†æ - åŸºå‡†æ–‡ä»¶ç‹¬æœ‰
    if len(unmatched_base) > 0 and tab_idx < len(tabs):
        with tabs[tab_idx]:
            tab_idx += 1
            st.markdown(f"#### {base_name} ä¸­ç‹¬æœ‰çš„æ¡æ¬¾ ({len(unmatched_base)})")
            st.text_area("æ¡æ¬¾å†…å®¹", unmatched_base[0] if unmatched_base else "", height=200)
    
    # æœªåŒ¹é…çš„æ¡æ¬¾åˆ†æ - å¯¹æ¯”æ–‡ä»¶ç‹¬æœ‰
    if len(unmatched_compare) > 0 and tab_idx < len(tabs):
        with tabs[tab_idx]:
            tab_idx += 1
            st.markdown(f"#### {compare_name} ä¸­ç‹¬æœ‰çš„æ¡æ¬¾ ({len(unmatched_compare)})")
            st.text_area("æ¡æ¬¾å†…å®¹", unmatched_compare[0] if unmatched_compare else "", height=200)

# åº”ç”¨ä¸»ç•Œé¢
st.title("ğŸ“„ ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·")
st.markdown("ç®€åŒ–ç‰ˆæ¡æ¬¾å¯¹æ¯”åˆ†æå·¥å…·")

# Qwen APIè®¾ç½®
with st.sidebar:
    st.subheader("Qwen API è®¾ç½®")
    qwen_api_key = st.text_input("è¯·è¾“å…¥Qwen APIå¯†é’¥", type="password")
    st.markdown(f"APIç«¯ç‚¹ï¼š`{QWEN_API_URL}`")

with st.form("upload_form"):
    st.subheader("åŸºå‡†æ–‡ä»¶")
    base_file = st.file_uploader("é€‰æ‹©åŸºå‡†PDFæ–‡ä»¶", type=["pdf"], key="base_file")
    
    st.subheader("å¯¹æ¯”æ–‡ä»¶")
    compare_files = st.file_uploader(
        "é€‰æ‹©éœ€è¦å¯¹æ¯”çš„PDFæ–‡ä»¶", 
        type=["pdf"], 
        key="compare_files",
        accept_multiple_files=True
    )
    
    submitted = st.form_submit_button("å¼€å§‹åˆ†æ")

if submitted and base_file and compare_files:
    # åˆ›å»ºæ€»ä½“è¿›åº¦è·Ÿè¸ª
    overall_progress = st.progress(0)
    total_steps = 1 + len(compare_files) * 2  # åŸºå‡†æ–‡ä»¶å¤„ç† + æ¯ä¸ªå¯¹æ¯”æ–‡ä»¶çš„2ä¸ªæ­¥éª¤
    current_step = 0
    
    with st.spinner("æ­£åœ¨è§£æåŸºå‡†PDFå†…å®¹..."):
        # æ˜¾ç¤ºåŸºå‡†æ–‡ä»¶å¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        base_text = extract_text_from_pdf(base_file, progress_bar)
        progress_bar.empty()
        
        current_step += 1
        overall_progress.progress(current_step / total_steps)
        
        if not base_text:
            st.error("æ— æ³•æå–åŸºå‡†æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹")
        else:
            st.success(f"åŸºå‡†æ–‡ä»¶ {base_file.name} æ–‡æœ¬æå–å®Œæˆ")
            
            # è§£æåŸºå‡†æ–‡ä»¶æ¡æ¬¾
            base_clauses = split_into_clauses(base_text, base_file.name)
            st.success(f"åŸºå‡†æ–‡ä»¶æ¡æ¬¾è§£æå®Œæˆï¼Œå…±è¯†åˆ«å‡º {len(base_clauses)} æ¡æ¡æ¬¾")
            
            # å¯¹æ¯ä¸ªå¯¹æ¯”æ–‡ä»¶è¿›è¡Œåˆ†æ
            for i, compare_file in enumerate(compare_files, 1):
                st.markdown(f"## åˆ†æ {i}/{len(compare_files)}: {compare_file.name}")
                
                # æå–å¯¹æ¯”æ–‡ä»¶æ–‡æœ¬
                with st.spinner(f"æ­£åœ¨æå– {compare_file.name} çš„æ–‡æœ¬..."):
                    progress_bar = st.progress(0)
                    compare_text = extract_text_from_pdf(compare_file, progress_bar)
                    progress_bar.empty()
                
                current_step += 1
                overall_progress.progress(current_step / total_steps)
                
                if not compare_text:
                    st.error(f"æ— æ³•æå– {compare_file.name} çš„æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
                    continue
                
                # åˆ†æå½“å‰å¯¹æ¯”æ–‡ä»¶ä¸åŸºå‡†æ–‡ä»¶
                analyze_single_comparison(
                    base_clauses, 
                    compare_text, 
                    base_file.name, 
                    compare_file.name, 
                    qwen_api_key
                )
                
                current_step += 1
                overall_progress.progress(current_step / total_steps)
                
                st.markdown("---")
        
        # å®Œæˆæ‰€æœ‰åˆ†æ
        overall_progress.empty()
        st.success("æ‰€æœ‰æ–‡æ¡£åˆ†æå·²å®Œæˆï¼")
        
elif submitted:
    if not base_file:
        st.error("è¯·ä¸Šä¼ åŸºå‡†PDFæ–‡ä»¶")
    if not compare_files:
        st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªå¯¹æ¯”PDFæ–‡ä»¶")
else:
    st.info('è¯·ä¸Šä¼ ä¸€ä¸ªåŸºå‡†PDFæ–‡ä»¶å’Œè‡³å°‘ä¸€ä¸ªå¯¹æ¯”PDFæ–‡ä»¶ï¼Œç„¶åç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®')

# æ·»åŠ é¡µè„š
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…· | ç®€åŒ–ç‰ˆ
</div>
""", unsafe_allow_html=True)
