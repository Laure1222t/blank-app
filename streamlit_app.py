import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba
import time
from typing import List, Tuple, Dict, Optional

# --------------------------
# åŸºç¡€é…ç½®ä¸åˆå§‹åŒ–
# --------------------------
# é¡µé¢é…ç½®ï¼ˆå¢åŠ åŠ è½½çŠ¶æ€ç®¡ç†ï¼‰
st.set_page_config(
    page_title="Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·ï¼ˆ1å¯¹å¤šï¼‰",
    page_icon="ğŸ“„",
    layout="wide"
)

# åˆå§‹åŒ–jiebaåˆ†è¯ï¼ˆæ·»åŠ è‡ªå®šä¹‰è¯å…¸æ”¯æŒï¼‰
jieba.initialize()
try:
    jieba.load_userdict("legal_dict.txt")  # å¯æ”¾ç½®æ³•å¾‹æœ¯è¯­è¯å…¸å¢å¼ºåˆ†è¯
except:
    pass  # æ— è¯å…¸æ—¶ä¸å½±å“åŸºç¡€åŠŸèƒ½

# è‡ªå®šä¹‰æ ·å¼ï¼ˆå¢å¼ºè§†è§‰åé¦ˆä¸å¯è¯»æ€§ï¼‰
st.markdown("""
<style>
    .stApp { max-width: 1400px; margin: 0 auto; }
    .file-selector { border: 1px solid #e0e0e0; padding: 15px; border-radius: 5px; margin-bottom: 15px; }
    .benchmark-label { color: #0066cc; font-weight: bold; }
    .target-label { color: #cc6600; font-weight: bold; }
    .highlight-conflict { background-color: #ffeeba; padding: 2px 4px; border-radius: 3px; }
    .clause-box { border-left: 4px solid #007bff; padding: 10px; margin: 10px 0; background-color: #f8f9fa; }
    .compliance-ok { border-left: 4px solid #28a745; }
    .compliance-warning { border-left: 4px solid #ffc107; }
    .compliance-conflict { border-left: 4px solid #dc3545; }
    .model-response { background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin: 10px 0; }
    .section-title { border-bottom: 2px solid #f0f2f6; padding-bottom: 8px; margin-top: 20px; }
    .analysis-card { border: 1px solid #eee; border-radius: 8px; padding: 15px; margin: 10px 0; }
    .status-badge { display: inline-block; padding: 3px 8px; border-radius: 12px; font-size: 0.8rem; }
</style>
""", unsafe_allow_html=True)

# APIé…ç½®ï¼ˆæ”¯æŒæ¨¡å‹é€‰æ‹©ï¼‰
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
SUPPORTED_MODELS = {
    "qwen-plus": "Qwen Plusï¼ˆå¹³è¡¡å‹ï¼Œæ¨èï¼‰",
    "qwen-max": "Qwen Maxï¼ˆé«˜ç²¾åº¦ï¼Œè¾ƒæ…¢ï¼‰",
    "qwen-turbo": "Qwen Turboï¼ˆå¿«é€Ÿå‹ï¼Œé€‚åˆåˆæ­¥åˆ†æï¼‰"
}

# --------------------------
# æ ¸å¿ƒåŠŸèƒ½ä¼˜åŒ–
# --------------------------
def call_qwen_api(prompt: str, api_key: str, model: str = "qwen-plus") -> Optional[str]:
    """è°ƒç”¨Qwenå¤§æ¨¡å‹APIï¼ˆå¢åŠ é‡è¯•æœºåˆ¶å’Œæ¨¡å‹é€‰æ‹©ï¼‰"""
    if not api_key:
        st.error("Qwen APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨å·¦ä¾§æ è¾“å…¥å¯†é’¥")
        return None
        
    max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡
    retry_delay = 3  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
    
    for attempt in range(max_retries + 1):
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1500
            }
            
            response = requests.post(
                QWEN_API_URL,
                headers=headers,
                json=data,
                timeout=60
            )
            
            # å¤„ç†æˆåŠŸå“åº”
            if response.status_code == 200:
                response_json = response.json()
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    return response_json["choices"][0]["message"]["content"]
                st.error("APIè¿”å›æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼ˆæ— æœ‰æ•ˆç»“æœï¼‰")
                return None
            
            # å¤„ç†é™æµ/ä¸´æ—¶é”™è¯¯ï¼ˆé‡è¯•ï¼‰
            elif response.status_code in [429, 502, 503] and attempt < max_retries:
                st.warning(f"APIè¯·æ±‚æš‚æ—¶å¤±è´¥ï¼ˆ{response.status_code}ï¼‰ï¼Œå°†åœ¨{retry_delay}ç§’åé‡è¯•ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(retry_delay)
                continue
            
            # å…¶ä»–é”™è¯¯ï¼ˆä¸é‡è¯•ï¼‰
            else:
                st.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”: {response.text[:200]}...")
                return None
                
        except requests.exceptions.Timeout:
            if attempt < max_retries:
                st.warning(f"APIè¯·æ±‚è¶…æ—¶ï¼Œå°†åœ¨{retry_delay}ç§’åé‡è¯•ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(retry_delay)
                continue
            st.error("APIè¯·æ±‚è¶…æ—¶ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            return None
        except Exception as e:
            st.error(f"è°ƒç”¨Qwen APIå¤±è´¥: {str(e)}")
            return None


def extract_text_from_pdf(file) -> str:
    """ä»PDFæå–æ–‡æœ¬ï¼ˆä¼˜åŒ–ä¸­æ–‡æ’ç‰ˆå’Œè¿›åº¦åé¦ˆï¼‰"""
    try:
        pdf_reader = PdfReader(file)
        text = ""
        total_pages = len(pdf_reader.pages)
        
        # æ˜¾ç¤ºæå–è¿›åº¦ï¼ˆå¤§æ–‡ä»¶å‹å¥½ï¼‰
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text() or ""
            # ä¼˜åŒ–ä¸­æ–‡å¤„ç†ï¼šä¿ç•™å¿…è¦ç©ºæ ¼ï¼Œä¿®å¤æ–­å¥
            page_text = page_text.replace("\n", "").replace("\r", "").replace("  ", " ")
            text += page_text
            
            # æ›´æ–°è¿›åº¦
            progress = (i + 1) / total_pages
            progress_bar.progress(progress)
            status_text.text(f"æ­£åœ¨æå–æ–‡æœ¬ï¼šç¬¬{i + 1}/{total_pages}é¡µ")
        
        progress_bar.empty()
        status_text.empty()
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""


def split_into_clauses(text: str) -> List[str]:
    """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ¡æ¬¾ï¼ˆå¢å¼ºæ¨¡å¼è¯†åˆ«å’Œè¿‡æ»¤ï¼‰"""
    # å¢å¼ºä¸­æ–‡æ¡æ¬¾æ¨¡å¼ï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
    patterns = [
        # æ ‡å‡†æ¡æ¬¾æ ¼å¼
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+æ¡\s*[ï¼š:]\s*.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+æ¡\s*[ï¼š:]|$)',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*|$)',
        # æ•°å­—ç¼–å·æ ¼å¼
        r'(\d+\.\s*.*?)(?=\d+\.\s*|$)',
        r'(\(\d+\)\s*.*?)(?=\(\d+\)\s*|$)',
        r'(\d+\)\s*.*?)(?=\d+\)\s*|$)',
        # ç‰¹æ®Šæ ‡è®°æ ¼å¼
        r'(ã€[^\ã€‘]+ã€‘\s*.*?)(?=ã€[^\ã€‘]+ã€‘\s*|$)',
        r'([A-Za-z]\.\s*.*?)(?=[A-Za-z]\.\s*|$)'
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:  # ç¡®ä¿æœ‰æ•ˆåˆ†å‰²
            # è¿‡æ»¤è¿‡çŸ­/æ— æ•ˆæ¡æ¬¾
            return [
                clause.strip() for clause in clauses 
                if clause.strip() and len(clause.strip()) > 15  # è¿‡æ»¤æçŸ­å†…å®¹
            ]
    
    # å…œåº•æ–¹æ¡ˆï¼šæŒ‰æ ‡ç‚¹åˆ†å‰²ï¼ˆæ›´æ™ºèƒ½çš„è¿‡æ»¤ï¼‰
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    return [
        p.strip() for p in paragraphs 
        if p.strip() and len(p.strip()) > 15 and not re.match(r'^\s*$', p)
    ]


def match_clauses(benchmark_clauses: List[str], target_clauses: List[str]) -> Tuple[List, List, List]:
    """åŒ¹é…åŸºå‡†æ¡æ¬¾ä¸ç›®æ ‡æ¡æ¬¾ï¼ˆä¼˜åŒ–åŒ¹é…é€»è¾‘ï¼Œé¿å…é‡å¤åŒ¹é…ï¼‰"""
    matched_pairs = []
    used_target_indices = set()  # è®°å½•å·²åŒ¹é…çš„ç›®æ ‡æ¡æ¬¾ç´¢å¼•
    benchmark_count = len(benchmark_clauses)
    
    # æ˜¾ç¤ºåŒ¹é…è¿›åº¦
    progress_bar = st.progress(0)
    
    for i, bench_clause in enumerate(benchmark_clauses):
        best_match = None
        best_ratio = 0.25  # ä¸­æ–‡åŒ¹é…é˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
        best_j = -1
        
        # åªåŒ¹é…æœªè¢«ä½¿ç”¨çš„ç›®æ ‡æ¡æ¬¾
        for j, target_clause in enumerate(target_clauses):
            if j not in used_target_indices:
                ratio = chinese_text_similarity(bench_clause, target_clause)
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = target_clause
                    best_j = j
        
        if best_match:
            matched_pairs.append((bench_clause, best_match, best_ratio))
            used_target_indices.add(best_j)
        
        # æ›´æ–°è¿›åº¦
        progress_bar.progress((i + 1) / benchmark_count)
    
    progress_bar.empty()
    
    # ä¼˜åŒ–æœªåŒ¹é…æ¡æ¬¾è®¡ç®—
    matched_bench_indices = {i for i, _ in enumerate(matched_pairs)}
    unmatched_bench = [
        clause for i, clause in enumerate(benchmark_clauses) 
        if i not in matched_bench_indices
    ]
    unmatched_target = [
        clause for j, clause in enumerate(target_clauses) 
        if j not in used_target_indices
    ]
    
    return matched_pairs, unmatched_bench, unmatched_target


# --------------------------
# è¾…åŠ©åŠŸèƒ½ä¼˜åŒ–
# --------------------------
def chinese_text_similarity(text1: str, text2: str) -> float:
    """è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆä¿ç•™åŸé€»è¾‘ï¼Œç¨³å®šå¯é ï¼‰"""
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    return SequenceMatcher(None, words1, words2).ratio()


def create_download_link(content: str, filename: str, text: str) -> str:
    """ç”Ÿæˆä¸‹è½½é“¾æ¥ï¼ˆå¢åŠ å®‰å…¨ç¼–ç ï¼‰"""
    b64 = base64.b64encode(content.encode("utf-8")).decode()
    return f'<a href="data:file/txt;base64,{b64}" download="{filename}" target="_blank">{text}</a>'


def generate_analysis_report(analysis_results: Dict) -> str:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆæ”¯æŒä¸‹è½½ï¼‰"""
    report = []
    report.append(f"=== {analysis_results['target_name']} ä¸ {analysis_results['bench_name']} åˆè§„æ€§åˆ†ææŠ¥å‘Š ===\n")
    
    # åŸºæœ¬ç»Ÿè®¡
    report.append("1. åŸºæœ¬ç»Ÿè®¡")
    report.append(f"- åŸºå‡†æ¡æ¬¾æ€»æ•°ï¼š{analysis_results['bench_count']}")
    report.append(f"- ç›®æ ‡æ¡æ¬¾æ€»æ•°ï¼š{analysis_results['target_count']}")
    report.append(f"- åŒ¹é…æ¡æ¬¾æ•°ï¼š{analysis_results['matched_count']}\n")
    
    # åŒ¹é…æ¡æ¬¾åˆ†æ
    report.append("2. åŒ¹é…æ¡æ¬¾åˆ†æ")
    for i, (bench_clause, target_clause, ratio) in enumerate(analysis_results["matched_pairs"]):
        report.append(f"\n--- åŒ¹é…å¯¹ {i + 1}ï¼ˆç›¸ä¼¼åº¦ï¼š{ratio:.2%}ï¼‰---")
        report.append(f"åŸºå‡†æ¡æ¬¾ï¼š{bench_clause}")
        report.append(f"ç›®æ ‡æ¡æ¬¾ï¼š{target_clause}")
        report.append(f"åˆ†æç»“æœï¼š{analysis_results['compliance_analyses'][i] or 'æ— åˆ†æç»“æœ'}\n")
    
    # æœªåŒ¹é…æ¡æ¬¾
    report.append("3. æœªåŒ¹é…æ¡æ¬¾")
    report.append(f"åŸºå‡†ç‹¬æœ‰çš„æ¡æ¬¾ï¼ˆ{len(analysis_results['unmatched_bench'])}æ¡ï¼‰ï¼š")
    for i, clause in enumerate(analysis_results['unmatched_bench'][:5]):
        report.append(f"- {clause[:100]}...")
    report.append(f"\nç›®æ ‡ç‹¬æœ‰çš„æ¡æ¬¾ï¼ˆ{len(analysis_results['unmatched_target'])}æ¡ï¼‰ï¼š")
    for i, clause in enumerate(analysis_results['unmatched_target'][:5]):
        report.append(f"- {clause[:100]}...")
    
    return "\n".join(report)


# --------------------------
# åˆ†æé€»è¾‘ä¼˜åŒ–
# --------------------------
def analyze_compliance_with_qwen(
    bench_clause: str, target_clause: str, 
    bench_name: str, target_name: str, 
    api_key: str, model: str
) -> str:
    """ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææ¡æ¬¾åˆè§„æ€§ï¼ˆä¼˜åŒ–æç¤ºè¯ï¼‰"""
    # æ›´ç²¾å‡†çš„ä¸­æ–‡æç¤ºè¯ï¼ˆå¼ºè°ƒæ³•å¾‹æ¡æ¬¾ç»†èŠ‚ï¼‰
    prompt = f"""
    ä½œä¸ºæ³•å¾‹æ¡æ¬¾åˆ†æä¸“å®¶ï¼Œè¯·ä»¥ã€Š{bench_name}ã€‹ä¸ºåŸºå‡†ï¼Œåˆ†æä»¥ä¸‹ä¸¤ä¸ªæ¡æ¬¾çš„åˆè§„æ€§ï¼š
    
    ã€åŸºå‡†æ¡æ¬¾ã€‘ï¼ˆæ¥è‡ªã€Š{bench_name}ã€‹ï¼‰ï¼š
    {bench_clause}
    
    ã€ç›®æ ‡æ¡æ¬¾ã€‘ï¼ˆæ¥è‡ªã€Š{target_name}ã€‹ï¼‰ï¼š
    {target_clause}
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ€»å­—æ•°æ§åˆ¶åœ¨800å­—å†…ï¼‰ï¼š
    1. ç›¸ä¼¼åº¦è¯„ä¼°ï¼šæ˜ç¡®é«˜/ä¸­/ä½ï¼Œå¹¶è¯´æ˜æ ¸å¿ƒä¾æ®ï¼ˆå¦‚æ¡æ¬¾ç›®çš„ã€çº¦æŸèŒƒå›´ï¼‰
    2. å·®å¼‚ç‚¹åˆ†æï¼šé€æ¡åˆ—å‡ºè¡¨è¿°ã€è¦æ±‚ã€è´£ä»»ç•Œå®šç­‰æ–¹é¢çš„å…·ä½“å·®å¼‚
    3. åˆè§„æ€§åˆ¤æ–­ï¼šæ˜ç¡®æ— å†²çª/è½»å¾®å†²çª/ä¸¥é‡å†²çªï¼ˆä»¥åŸºå‡†æ¡æ¬¾ä¸ºä¾æ®ï¼‰
    4. å†²çªå½±å“ï¼ˆå¦‚å­˜åœ¨ï¼‰ï¼šè¯´æ˜å†²çªå¯èƒ½å¯¼è‡´çš„å®é™…é—®é¢˜ï¼ˆå¦‚æ³•å¾‹é£é™©ã€æ‰§è¡ŒçŸ›ç›¾ï¼‰
    5. å»ºè®®ï¼šé’ˆå¯¹å·®å¼‚/å†²çªç»™å‡ºå…·ä½“ä¿®æ”¹æ–¹å‘ï¼ˆå‚è€ƒåŸºå‡†æ¡æ¬¾è¡¨è¿°ï¼‰
    
    æ³¨æ„ï¼šéœ€ç‰¹åˆ«å…³æ³¨ä¸­æ–‡æ³•å¾‹æœ¯è¯­å·®å¼‚ï¼ˆå¦‚"åº”å½“"vs"å¿…é¡»"ã€"ä¸å¾—"vs"ç¦æ­¢"çš„æ³•å¾‹æ•ˆåŠ›åŒºåˆ«ï¼‰ã€‚
    """
    return call_qwen_api(prompt, api_key, model)


def analyze_single_target(
    bench_text: str, target_text: str, 
    bench_name: str, target_name: str, 
    api_key: str, model: str
) -> Dict:
    """åˆ†æå•ä¸ªç›®æ ‡æ–‡ä»¶ï¼ˆå¢åŠ ä¸­é—´ç»“æœç¼“å­˜ï¼‰"""
    # æ¡æ¬¾åˆ†å‰²ï¼ˆå¤ç”¨å·²å¤„ç†ç»“æœï¼‰
    bench_clauses = split_into_clauses(bench_text)
    target_clauses = split_into_clauses(target_text)
    
    # æ¡æ¬¾åŒ¹é…
    matched_pairs, unmatched_bench, unmatched_target = match_clauses(bench_clauses, target_clauses)
    
    # åˆè§„æ€§åˆ†æï¼ˆæ”¯æŒä¸­æ–­åç»§ç»­ï¼‰
    compliance_analyses = []
    for i, (bench_clause, target_clause, ratio) in enumerate(matched_pairs):
        with st.expander(f"æ­£åœ¨åˆ†æåŒ¹é…å¯¹ {i + 1}/{len(matched_pairs)}ï¼ˆç‚¹å‡»æŸ¥çœ‹æ¡æ¬¾ï¼‰", expanded=False):
            st.text(f"åŸºå‡†æ¡æ¬¾ï¼š{bench_clause[:100]}...")
            st.text(f"ç›®æ ‡æ¡æ¬¾ï¼š{target_clause[:100]}...")
        
        analysis = analyze_compliance_with_qwen(
            bench_clause, target_clause, bench_name, target_name, api_key, model
        )
        compliance_analyses.append(analysis)
    
    return {
        "bench_name": bench_name,
        "target_name": target_name,
        "bench_count": len(bench_clauses),
        "target_count": len(target_clauses),
        "matched_count": len(matched_pairs),
        "matched_pairs": matched_pairs,
        "unmatched_bench": unmatched_bench,
        "unmatched_target": unmatched_target,
        "compliance_analyses": compliance_analyses
    }


# --------------------------
# ç•Œé¢ä¸äº¤äº’ä¼˜åŒ–
# --------------------------
def show_multi_target_analysis(
    bench_text: str, target_files: List, 
    bench_name: str, api_key: str, model: str
):
    """æ˜¾ç¤ºå¤šç›®æ ‡åˆ†æç»“æœï¼ˆå¢åŠ ç­›é€‰å’Œä¸‹è½½ï¼‰"""
    # åŸºå‡†æ¡æ¬¾é¢„å¤„ç†ï¼ˆåªå¤„ç†ä¸€æ¬¡ï¼‰
    bench_clauses = split_into_clauses(bench_text)
    st.success(f"åŸºå‡†æ–‡ä»¶æ¡æ¬¾è§£æå®Œæˆï¼š{bench_name} è¯†åˆ«å‡º {len(bench_clauses)} æ¡æ¡æ¬¾")

    # ç›®æ ‡æ–‡ä»¶é€‰æ‹©å™¨ï¼ˆæ”¯æŒæœç´¢ï¼‰
    st.subheader("ğŸ” é€‰æ‹©ç›®æ ‡æ–‡ä»¶è¿›è¡Œå¯¹æ¯”")
    target_names = [f.name for f in target_files]
    selected_targets = st.multiselect(
        "å·²ä¸Šä¼ ç›®æ ‡æ–‡ä»¶ï¼ˆå¯æœç´¢ï¼‰",
        options=target_names,
        default=target_names[:2],  # é»˜è®¤é€‰æ‹©å‰2ä¸ª
        format_func=lambda x: x  # æ”¯æŒæœç´¢åŒ¹é…
    )

    if not selected_targets:
