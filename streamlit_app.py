import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba
import time
from typing import List, Tuple, Dict, Optional

# --------------------------
# åŸºç¡€é…ç½®ä¸åˆå§‹åŒ–
# --------------------------
# é¡µé¢é…ç½®ï¼ˆå¢åŠ åŠ è½½çŠ¶æ€ç®¡ç†ï¼‰
st.set_page_config(
    page_title="Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·ï¼ˆ1å¯¹å¤šï¼‰",
    page_icon="ğŸ“„",
    layout="wide"
)

# åˆå§‹åŒ–jiebaåˆ†è¯ï¼ˆæ·»åŠ è‡ªå®šä¹‰è¯å…¸æ”¯æŒï¼‰
jieba.initialize()
try:
    jieba.load_userdict("legal_dict.txt")  # å¯æ”¾ç½®æ³•å¾‹æœ¯è¯­è¯å…¸å¢å¼ºåˆ†è¯
except:
    pass  # æ— è¯å…¸æ—¶ä¸å½±å“åŸºç¡€åŠŸèƒ½

# è‡ªå®šä¹‰æ ·å¼ï¼ˆå¢å¼ºè§†è§‰åé¦ˆä¸å¯è¯»æ€§ï¼‰
st.markdown("""
<style>
    .stApp { max-width: 1400px; margin: 0 auto; }
    .file-selector { border: 1px solid #e0e0e0; padding: 15px; border-radius: 5px; margin-bottom: 15px; }
    .benchmark-label { color: #0066cc; font-weight: bold; }
    .target-label { color: #cc6600; font-weight: bold; }
    .highlight-conflict { background-color: #ffeeba; padding: 2px 4px; border-radius: 3px; }
    .clause-box { border-left: 4px solid #007bff; padding: 10px; margin: 10px 0; background-color: #f8f9fa; }
    .compliance-ok { border-left: 4px solid #28a745; }
    .compliance-warning { border-left: 4px solid #ffc107; }
    .compliance-conflict { border-left: 4px solid #dc3545; }
    .model-response { background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin: 10px 0; }
    .section-title { border-bottom: 2px solid #f0f2f6; padding-bottom: 8px; margin-top: 20px; }
    .analysis-card { border: 1px solid #eee; border-radius: 8px; padding: 15px; margin: 10px 0; }
    .status-badge { display: inline-block; padding: 3px 8px; border-radius: 12px; font-size: 0.8rem; }
</style>
""", unsafe_allow_html=True)

# APIé…ç½®ï¼ˆæ”¯æŒæ¨¡å‹é€‰æ‹©ï¼‰
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
SUPPORTED_MODELS = {
    "qwen-plus": "Qwen Plusï¼ˆå¹³è¡¡å‹ï¼Œæ¨èï¼‰",
    "qwen-max": "Qwen Maxï¼ˆé«˜ç²¾åº¦ï¼Œè¾ƒæ…¢ï¼‰",
    "qwen-turbo": "Qwen Turboï¼ˆå¿«é€Ÿå‹ï¼Œé€‚åˆåˆæ­¥åˆ†æï¼‰"
}

# --------------------------
# æ ¸å¿ƒåŠŸèƒ½ä¼˜åŒ–
# --------------------------
def call_qwen_api(prompt: str, api_key: str, model: str = "qwen-plus") -> Optional[str]:
    """è°ƒç”¨Qwenå¤§æ¨¡å‹APIï¼ˆå¢åŠ é‡è¯•æœºåˆ¶å’Œæ¨¡å‹é€‰æ‹©ï¼‰"""
    if not api_key:
        st.error("Qwen APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨å·¦ä¾§æ è¾“å…¥å¯†é’¥")
        return None
        
    max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡
    retry_delay = 3  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
    
    for attempt in range(max_retries + 1):
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1500
            }
            
            response = requests.post(
                QWEN_API_URL,
                headers=headers,
                json=data,
                timeout=60
            )
            
            # å¤„ç†æˆåŠŸå“åº”
            if response.status_code == 200:
                response_json = response.json()
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    return response_json["choices"][0]["message"]["content"]
                st.error("APIè¿”å›æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼ˆæ— æœ‰æ•ˆç»“æœï¼‰")
                return None
            
            # å¤„ç†é™æµ/ä¸´æ—¶é”™è¯¯ï¼ˆé‡è¯•ï¼‰
            elif response.status_code in [429, 502, 503] and attempt < max_retries:
                st.warning(f"APIè¯·æ±‚æš‚æ—¶å¤±è´¥ï¼ˆ{response.status_code}ï¼‰ï¼Œå°†åœ¨{retry_delay}ç§’åé‡è¯•ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(retry_delay)
                continue
            
            # å…¶ä»–é”™è¯¯ï¼ˆä¸é‡è¯•ï¼‰
            else:
                st.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”: {response.text[:200]}...")
                return None
                
        except requests.exceptions.Timeout:
            if attempt < max_retries:
                st.warning(f"APIè¯·æ±‚è¶…æ—¶ï¼Œå°†åœ¨{retry_delay}ç§’åé‡è¯•ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(retry_delay)
                continue
            st.error("APIè¯·æ±‚è¶…æ—¶ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            return None
        except Exception as e:
            st.error(f"è°ƒç”¨Qwen APIå¤±è´¥: {str(e)}")
            return None


def extract_text_from_pdf(file) -> str:
    """ä»PDFæå–æ–‡æœ¬ï¼ˆä¼˜åŒ–ä¸­æ–‡æ’ç‰ˆå’Œè¿›åº¦åé¦ˆï¼‰"""
    try:
        pdf_reader = PdfReader(file)
        text = ""
        total_pages = len(pdf_reader.pages)
        
        # æ˜¾ç¤ºæå–è¿›åº¦ï¼ˆå¤§æ–‡ä»¶å‹å¥½ï¼‰
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text() or ""
            # ä¼˜åŒ–ä¸­æ–‡å¤„ç†ï¼šä¿ç•™å¿…è¦ç©ºæ ¼ï¼Œä¿®å¤æ–­å¥
            page_text = page_text.replace("\n", "").replace("\r", "").replace("  ", " ")
            text += page_text
            
            # æ›´æ–°è¿›åº¦
            progress = (i + 1) / total_pages
            progress_bar.progress(progress)
            status_text.text(f"æ­£åœ¨æå–æ–‡æœ¬ï¼šç¬¬{i + 1}/{total_pages}é¡µ")
        
        progress_bar.empty()
        status_text.empty()
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""


def split_into_clauses(text: str) -> List[str]:
    """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ¡æ¬¾ï¼ˆå¢å¼ºæ¨¡å¼è¯†åˆ«å’Œè¿‡æ»¤ï¼‰"""
    # å¢å¼ºä¸­æ–‡æ¡æ¬¾æ¨¡å¼ï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
    patterns = [
        # æ ‡å‡†æ¡æ¬¾æ ¼å¼
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+æ¡\s*[ï¼š:]\s*.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+æ¡\s*[ï¼š:]|$)',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*|$)',
        # æ•°å­—ç¼–å·æ ¼å¼
        r'(\d+\.\s*.*?)(?=\d+\.\s*|$)',
        r'(\(\d+\)\s*.*?)(?=\(\d+\)\s*|$)',
        r'(\d+\)\s*.*?)(?=\d+\)\s*|$)',
        # ç‰¹æ®Šæ ‡è®°æ ¼å¼
        r'(ã€[^\ã€‘]+ã€‘\s*.*?)(?=ã€[^\ã€‘]+ã€‘\s*|$)',
        r'([A-Za-z]\.\s*.*?)(?=[A-Za-z]\.\s*|$)'
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:  # ç¡®ä¿æœ‰æ•ˆåˆ†å‰²
            # è¿‡æ»¤è¿‡çŸ­/æ— æ•ˆæ¡æ¬¾
            return [
                clause.strip() for clause in clauses 
                if clause.strip() and len(clause.strip()) > 15  # è¿‡æ»¤æçŸ­å†…å®¹
            ]
    
    # å…œåº•æ–¹æ¡ˆï¼šæŒ‰æ ‡ç‚¹åˆ†å‰²ï¼ˆæ›´æ™ºèƒ½çš„è¿‡æ»¤ï¼‰
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    return [
        p.strip() for p in paragraphs 
        if p.strip() and len(p.strip()) > 15 and not re.match(r'^\s*$', p)
    ]


def match_clauses(benchmark_clauses: List[str], target_clauses: List[str]) -> Tuple[List, List, List]:
    """åŒ¹é…åŸºå‡†æ¡æ¬¾ä¸ç›®æ ‡æ¡æ¬¾ï¼ˆä¼˜åŒ–åŒ¹é…é€»è¾‘ï¼Œé¿å…é‡å¤åŒ¹é…ï¼‰"""
    matched_pairs = []
    used_target_indices = set()  # è®°å½•å·²åŒ¹é…çš„ç›®æ ‡æ¡æ¬¾ç´¢å¼•
    benchmark_count = len(benchmark_clauses)
    
    # æ˜¾ç¤ºåŒ¹é…è¿›åº¦
    progress_bar = st.progress(0)
    
    for i, bench_clause in enumerate(benchmark_clauses):
        best_match = None
        best_ratio = 0.25  # ä¸­æ–‡åŒ¹é…é˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
        best_j = -1
        
        # åªåŒ¹é…æœªè¢«ä½¿ç”¨çš„ç›®æ ‡æ¡æ¬¾
        for j, target_clause in enumerate(target_clauses):
            if j not in used_target_indices:
                ratio = chinese_text_similarity(bench_clause, target_clause)
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = target_clause
                    best_j = j
        
        if best_match:
            matched_pairs.append((bench_clause, best_match, best_ratio))
            used_target_indices.add(best_j)
        
        # æ›´æ–°è¿›åº¦
        progress_bar.progress((i + 1) / benchmark_count)
    
    progress_bar.empty()
    
    # ä¼˜åŒ–æœªåŒ¹é…æ¡æ¬¾è®¡ç®—
    matched_bench_indices = {i for i, _ in enumerate(matched_pairs)}
    unmatched_bench = [
        clause for i, clause in enumerate(benchmark_clauses) 
        if i not in matched_bench_indices
    ]
    unmatched_target = [
        clause for j, clause in enumerate(target_clauses) 
        if j not in used_target_indices
    ]
    
    return matched_pairs, unmatched_bench, unmatched_target


# --------------------------
# è¾…åŠ©åŠŸèƒ½ä¼˜åŒ–
# --------------------------
def chinese_text_similarity(text1: str, text2: str) -> float:
    """è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆä¿ç•™åŸé€»è¾‘ï¼Œç¨³å®šå¯é ï¼‰"""
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    return SequenceMatcher(None, words1, words2).ratio()


def create_download_link(content: str, filename: str, text: str) -> str:
    """ç”Ÿæˆä¸‹è½½é“¾æ¥ï¼ˆå¢åŠ å®‰å…¨ç¼–ç ï¼‰"""
    b64 = base64.b64encode(content.encode("utf-8")).decode()
    return f'<a href="data:file/txt;base64,{b64}" download="{filename}" target="_blank">{text}</a>'


def generate_analysis_report(analysis_results: Dict) -> str:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆæ”¯æŒä¸‹è½½ï¼‰"""
    report = []
    report.append(f"=== {analysis_results['target_name']} ä¸ {analysis_results['bench_name']} åˆè§„æ€§åˆ†ææŠ¥å‘Š ===\n")
    
    # åŸºæœ¬ç»Ÿè®¡
    report.append("1. åŸºæœ¬ç»Ÿè®¡")
    report.append(f"- åŸºå‡†æ¡æ¬¾æ€»æ•°ï¼š{analysis_results['bench_count']}")
    report.append(f"- ç›®æ ‡æ¡æ¬¾æ€»æ•°ï¼š{analysis_results['target_count']}")
    report.append(f"- åŒ¹é…æ¡æ¬¾æ•°ï¼š{analysis_results['matched_count']}\n")
    
    # åŒ¹é…æ¡æ¬¾åˆ†æ
    report.append("2. åŒ¹é…æ¡æ¬¾åˆ†æ")
    for i, (bench_clause, target_clause, ratio) in enumerate(analysis_results["matched_pairs"]):
        report.append(f"\n--- åŒ¹é…å¯¹ {i + 1}ï¼ˆç›¸ä¼¼åº¦ï¼š{ratio:.2%}ï¼‰---")
        report.append(f"åŸºå‡†æ¡æ¬¾ï¼š{bench_clause}")
        report.append(f"ç›®æ ‡æ¡æ¬¾ï¼š{target_clause}")
        report.append(f"åˆ†æç»“æœï¼š{analysis_results['compliance_analyses'][i] or 'æ— åˆ†æç»“æœ'}\n")
    
    # æœªåŒ¹é…æ¡æ¬¾
    report.append("3. æœªåŒ¹é…æ¡æ¬¾")
    report.append(f"åŸºå‡†ç‹¬æœ‰çš„æ¡æ¬¾ï¼ˆ{len(analysis_results['unmatched_bench'])}æ¡ï¼‰ï¼š")
    for i, clause in enumerate(analysis_results['unmatched_bench'][:5]):
        report.append(f"- {clause[:100]}...")
    report.append(f"\nç›®æ ‡ç‹¬æœ‰çš„æ¡æ¬¾ï¼ˆ{len(analysis_results['unmatched_target'])}æ¡ï¼‰ï¼š")
    for i, clause in enumerate(analysis_results['unmatched_target'][:5]):
        report.append(f"- {clause[:100]}...")
    
    return "\n".join(report)


# --------------------------
# åˆ†æé€»è¾‘ä¼˜åŒ–
# --------------------------
def analyze_compliance_with_qwen(
    bench_clause: str, target_clause: str, 
    bench_name: str, target_name: str, 
    api_key: str, model: str
) -> str:
    """ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææ¡æ¬¾åˆè§„æ€§ï¼ˆä¼˜åŒ–æç¤ºè¯ï¼‰"""
    # æ›´ç²¾å‡†çš„ä¸­æ–‡æç¤ºè¯ï¼ˆå¼ºè°ƒæ³•å¾‹æ¡æ¬¾ç»†èŠ‚ï¼‰
    prompt = f"""
    ä½œä¸ºæ³•å¾‹æ¡æ¬¾åˆ†æä¸“å®¶ï¼Œè¯·ä»¥ã€Š{bench_name}ã€‹ä¸ºåŸºå‡†ï¼Œåˆ†æä»¥ä¸‹ä¸¤ä¸ªæ¡æ¬¾çš„åˆè§„æ€§ï¼š
    
    ã€åŸºå‡†æ¡æ¬¾ã€‘ï¼ˆæ¥è‡ªã€Š{bench_name}ã€‹ï¼‰ï¼š
    {bench_clause}
    
    ã€ç›®æ ‡æ¡æ¬¾ã€‘ï¼ˆæ¥è‡ªã€Š{target_name}ã€‹ï¼‰ï¼š
    {target_clause}
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„åˆ†æï¼ˆæ€»å­—æ•°æ§åˆ¶åœ¨800å­—å†…ï¼‰ï¼š
    1. ç›¸ä¼¼åº¦è¯„ä¼°ï¼šæ˜ç¡®é«˜/ä¸­/ä½ï¼Œå¹¶è¯´æ˜æ ¸å¿ƒä¾æ®ï¼ˆå¦‚æ¡æ¬¾ç›®çš„ã€çº¦æŸèŒƒå›´ï¼‰
    2. å·®å¼‚ç‚¹åˆ†æï¼šé€æ¡åˆ—å‡ºè¡¨è¿°ã€è¦æ±‚ã€è´£ä»»ç•Œå®šç­‰æ–¹é¢çš„å…·ä½“å·®å¼‚
    3. åˆè§„æ€§åˆ¤æ–­ï¼šæ˜ç¡®æ— å†²çª/è½»å¾®å†²çª/ä¸¥é‡å†²çªï¼ˆä»¥åŸºå‡†æ¡æ¬¾ä¸ºä¾æ®ï¼‰
    4. å†²çªå½±å“ï¼ˆå¦‚å­˜åœ¨ï¼‰ï¼šè¯´æ˜å†²çªå¯èƒ½å¯¼è‡´çš„å®é™…é—®é¢˜ï¼ˆå¦‚æ³•å¾‹é£é™©ã€æ‰§è¡ŒçŸ›ç›¾ï¼‰
    5. å»ºè®®ï¼šé’ˆå¯¹å·®å¼‚/å†²çªç»™å‡ºå…·ä½“ä¿®æ”¹æ–¹å‘ï¼ˆå‚è€ƒåŸºå‡†æ¡æ¬¾è¡¨è¿°ï¼‰
    
    æ³¨æ„ï¼šéœ€ç‰¹åˆ«å…³æ³¨ä¸­æ–‡æ³•å¾‹æœ¯è¯­å·®å¼‚ï¼ˆå¦‚"åº”å½“"vs"å¿…é¡»"ã€"ä¸å¾—"vs"ç¦æ­¢"çš„æ³•å¾‹æ•ˆåŠ›åŒºåˆ«ï¼‰ã€‚
    """
    return call_qwen_api(prompt, api_key, model)


def analyze_single_target(
    bench_text: str, target_text: str, 
    bench_name: str, target_name: str, 
    api_key: str, model: str
) -> Dict:
    """åˆ†æå•ä¸ªç›®æ ‡æ–‡ä»¶ï¼ˆå¢åŠ ä¸­é—´ç»“æœç¼“å­˜ï¼‰"""
    # æ¡æ¬¾åˆ†å‰²ï¼ˆå¤ç”¨å·²å¤„ç†ç»“æœï¼‰
    bench_clauses = split_into_clauses(bench_text)
    target_clauses = split_into_clauses(target_text)
    
    # æ¡æ¬¾åŒ¹é…
    matched_pairs, unmatched_bench, unmatched_target = match_clauses(bench_clauses, target_clauses)
    
    # åˆè§„æ€§åˆ†æï¼ˆæ”¯æŒä¸­æ–­åç»§ç»­ï¼‰
    compliance_analyses = []
    for i, (bench_clause, target_clause, ratio) in enumerate(matched_pairs):
        with st.expander(f"æ­£åœ¨åˆ†æåŒ¹é…å¯¹ {i + 1}/{len(matched_pairs)}ï¼ˆç‚¹å‡»æŸ¥çœ‹æ¡æ¬¾ï¼‰", expanded=False):
            st.text(f"åŸºå‡†æ¡æ¬¾ï¼š{bench_clause[:100]}...")
            st.text(f"ç›®æ ‡æ¡æ¬¾ï¼š{target_clause[:100]}...")
        
        analysis = analyze_compliance_with_qwen(
            bench_clause, target_clause, bench_name, target_name, api_key, model
        )
        compliance_analyses.append(analysis)
    
    return {
        "bench_name": bench_name,
        "target_name": target_name,
        "bench_count": len(bench_clauses),
        "target_count": len(target_clauses),
        "matched_count": len(matched_pairs),
        "matched_pairs": matched_pairs,
        "unmatched_bench": unmatched_bench,
        "unmatched_target": unmatched_target,
        "compliance_analyses": compliance_analyses
    }


# --------------------------
# ç•Œé¢ä¸äº¤äº’ä¼˜åŒ–
# --------------------------
def show_multi_target_analysis(
    bench_text: str, target_files: List, 
    bench_name: str, api_key: str, model: str
):
    """æ˜¾ç¤ºå¤šç›®æ ‡åˆ†æç»“æœï¼ˆå¢åŠ ç­›é€‰å’Œä¸‹è½½ï¼‰"""
    # åŸºå‡†æ¡æ¬¾é¢„å¤„ç†ï¼ˆåªå¤„ç†ä¸€æ¬¡ï¼‰
    bench_clauses = split_into_clauses(bench_text)
    st.success(f"åŸºå‡†æ–‡ä»¶æ¡æ¬¾è§£æå®Œæˆï¼š{bench_name} è¯†åˆ«å‡º {len(bench_clauses)} æ¡æ¡æ¬¾")

    # ç›®æ ‡æ–‡ä»¶é€‰æ‹©å™¨ï¼ˆæ”¯æŒæœç´¢ï¼‰
    st.subheader("ğŸ” é€‰æ‹©ç›®æ ‡æ–‡ä»¶è¿›è¡Œå¯¹æ¯”")
    target_names = [f.name for f in target_files]
    selected_targets = st.multiselect(
        "å·²ä¸Šä¼ ç›®æ ‡æ–‡ä»¶ï¼ˆå¯æœç´¢ï¼‰",
        options=target_names,
        default=target_names[:2],  # é»˜è®¤é€‰æ‹©å‰2ä¸ª
        format_func=lambda x: x  # æ”¯æŒæœç´¢åŒ¹é…
    )

    if not selected_targets:
        st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç›®æ ‡æ–‡ä»¶")
        return

    # æ‰¹é‡åˆ†æ
    for target_name in selected_targets:
        # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶å¯¹è±¡
        target_file = next(f for f in target_files if f.name == target_name)
        target_text = extract_text_from_pdf(target_file)
        
        if not target_text:
            st.error(f"æ— æ³•æå– {target_name} çš„æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
            continue

        # æ˜¾ç¤ºå•ä¸ªç›®æ ‡åˆ†æç»“æœ
        st.divider()
        st.header(f"ğŸ“Œ {target_name} ä¸ {bench_name} å¯¹æ¯”åˆ†æ")
        
        # æ‰§è¡Œåˆ†æ
        with st.spinner(f"æ­£åœ¨åˆ†æ {target_name}..."):
            result = analyze_single_target(
                bench_text, target_text, bench_name, target_name, api_key, model
            )
        
        # ç»Ÿè®¡ä¿¡æ¯å¡ç‰‡
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(f"**{bench_name} æ¡æ¬¾æ•°**\n{result['bench_count']}")
        with col2:
            st.info(f"**{target_name} æ¡æ¬¾æ•°**\n{result['target_count']}")
        with col3:
            st.info(f"**åŒ¹é…æ¡æ¬¾æ•°**\n{result['matched_count']}")

        # ç”Ÿæˆå¹¶æä¾›æŠ¥å‘Šä¸‹è½½
        report = generate_analysis_report(result)
        st.markdown(
            create_download_link(report, f"{target_name}_åˆè§„æ€§åˆ†ææŠ¥å‘Š.txt", "ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š"),
            unsafe_allow_html=True
        )

        # è¯¦ç»†åˆ†æï¼ˆå¸¦æŠ˜å é¢æ¿ï¼‰
        with st.expander("æ¡æ¬¾åŒ¹é…åŠåˆè§„æ€§åˆ†æï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=True):
            for i in range(result["matched_count"]):
                st.markdown(f"### åŒ¹é…å¯¹ {i+1}ï¼ˆç›¸ä¼¼åº¦: {result['matched_pairs'][i][2]:.2%}ï¼‰")
                
                # æ¡æ¬¾å¯¹æ¯”å±•ç¤º
                col_a, col_b = st.columns(2)
                with col_a:
                    st.markdown(f'<div class="clause-box compliance-ok"><strong>{bench_name} æ¡æ¬¾:</strong><br>{result["matched_pairs"][i][0]}</div>', unsafe_allow_html=True)
                with col_b:
                    st.markdown(f'<div class="clause-box"><strong>{target_name} æ¡æ¬¾:</strong><br>{result["matched_pairs"][i][1]}</div>', unsafe_allow_html=True)
                
                # åˆè§„æ€§åˆ†æç»“æœ
                if result["compliance_analyses"][i]:
                    # æå–åˆè§„æ€§ç»“è®ºç”¨äºå¿«é€Ÿæ ‡è¯†
                    analysis_text = result["compliance_analyses"][i]
                    if "ä¸¥é‡å†²çª" in analysis_text:
                        badge_class = "compliance-conflict"
                        badge_text = "ä¸¥é‡å†²çª"
                    elif "è½»å¾®å†²çª" in analysis_text:
                        badge_class = "compliance-warning"
                        badge_text = "è½»å¾®å†²çª"
                    else:
                        badge_class = "compliance-ok"
                        badge_text = "æ— å†²çª"
                    
                    st.markdown(f'<span class="status-badge {badge_class}">{badge_text}</span>', unsafe_allow_html=True)
                    st.markdown(
                        f'<div class="model-response"><strong>åˆè§„æ€§åˆ†æ:</strong><br>{analysis_text}</div>',
                        unsafe_allow_html=True
                    )
                st.divider()

        # æœªåŒ¹é…æ¡æ¬¾åˆ†æï¼ˆå¸¦å±•å¼€/æŠ˜å ï¼‰
        with st.expander(f"æœªåŒ¹é…æ¡æ¬¾åˆ†æï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=False):
            col_un1, col_un2 = st.columns(2)
            
            with col_un1:
                st.markdown(f"#### {bench_name} ç‹¬æœ‰çš„æ¡æ¬¾ï¼ˆ{len(result['unmatched_bench'])}ï¼‰")
                for i, clause in enumerate(result["unmatched_bench"][:5]):
                    with st.expander(f"æ¡æ¬¾ {i+1}ï¼ˆç‚¹å‡»æŸ¥çœ‹åˆ†æï¼‰", expanded=False):
                        st.markdown(f'<div class="clause-box">{clause}</div>', unsafe_allow_html=True)
                        # å¯¹æœªåŒ¹é…çš„åŸºå‡†æ¡æ¬¾è¿›è¡Œå•ç‹¬åˆ†æ
                        analysis = analyze_standalone_clause_with_qwen(clause, bench_name, api_key, model)
                        if analysis:
                            st.markdown(f'<div class="model-response"><strong>æ¡æ¬¾åˆ†æ:</strong><br>{analysis}</div>', unsafe_allow_html=True)
                
                if len(result["unmatched_bench"]) > 5:
                    st.info(f"å…± {len(result['unmatched_bench'])} æ¡ï¼Œä»…æ˜¾ç¤ºå‰5æ¡")

            with col_un2:
                st.markdown(f"#### {target_name} ç‹¬æœ‰çš„æ¡æ¬¾ï¼ˆ{len(result['unmatched_target'])}ï¼‰")
                for i, clause in enumerate(result["unmatched_target"][:5]):
                    with st.expander(f"æ¡æ¬¾ {i+1}ï¼ˆç‚¹å‡»æŸ¥çœ‹åˆ†æï¼‰", expanded=False):
                        st.markdown(f'<div class="clause-box">{clause}</div>', unsafe_allow_html=True)
                        # å¯¹æœªåŒ¹é…çš„ç›®æ ‡æ¡æ¬¾è¿›è¡Œå•ç‹¬åˆ†æ
                        analysis = analyze_standalone_clause_with_qwen(clause, target_name, api_key, model)
                        if analysis:
                            st.markdown(f'<div class="model-response"><strong>æ¡æ¬¾åˆ†æ:</strong><br>{analysis}</div>', unsafe_allow_html=True)
                
                if len(result["unmatched_target"]) > 5:
                    st.info(f"å…± {len(result['unmatched_target'])} æ¡ï¼Œä»…æ˜¾ç¤ºå‰5æ¡")


# ä¸»ç•Œé¢ä¼˜åŒ–
def main():
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆä¿å­˜ä¸­é—´ç»“æœï¼‰
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = {}

    st.title("ğŸ“„ Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·ï¼ˆ1å¯¹å¤šï¼‰")
    st.markdown("æ”¯æŒ1ä¸ªåŸºå‡†æ–‡ä»¶ä¸å¤šä¸ªç›®æ ‡æ–‡ä»¶çš„æ¡æ¬¾åˆè§„æ€§æ¯”å¯¹ï¼Œè‡ªåŠ¨è¯†åˆ«æ³•å¾‹æ¡æ¬¾å¹¶åˆ†æå·®å¼‚")

    # ä¾§è¾¹æ é…ç½®å¢å¼º
    with st.sidebar:
        st.subheader("âš™ï¸ åˆ†æé…ç½®")
        
        # APIå¯†é’¥è®¾ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡ï¼‰
        qwen_api_key = st.text_input(
            "è¯·è¾“å…¥Qwen APIå¯†é’¥", 
            type="password",
            help="è·å–å¯†é’¥: https://dashscope.aliyun.com/"
        )
        
        # æ¨¡å‹é€‰æ‹©
        model_choice = st.selectbox(
            "é€‰æ‹©Qwenæ¨¡å‹",
            options=list(SUPPORTED_MODELS.keys()),
            format_func=lambda x: SUPPORTED_MODELS[x],
            index=0  # é»˜è®¤é€‰æ‹©qwen-plus
        )
        
        # é«˜çº§é€‰é¡¹ï¼ˆæŠ˜å ï¼‰
        with st.expander("é«˜çº§é€‰é¡¹", expanded=False):
            similarity_threshold = st.slider(
                "æ¡æ¬¾åŒ¹é…é˜ˆå€¼", 
                min_value=0.1, 
                max_value=0.5, 
                value=0.25, 
                step=0.05,
                help="å€¼è¶Šé«˜ï¼ŒåŒ¹é…æ¡ä»¶è¶Šä¸¥æ ¼"
            )
            max_display_clauses = st.slider(
                "æœ€å¤§æ˜¾ç¤ºæ¡æ¬¾æ•°",
                min_value=3,
                max_value=10,
                value=5,
                step=1
            )
        
        st.divider()
        st.info("""
        ä½¿ç”¨æ­¥éª¤ï¼š
        1. è¾“å…¥Qwen APIå¯†é’¥
        2. ä¸Šä¼ 1ä¸ªåŸºå‡†æ–‡ä»¶ï¼ˆä½œä¸ºåˆè§„æ ‡å‡†ï¼‰
        3. ä¸Šä¼ å¤šä¸ªç›®æ ‡æ–‡ä»¶ï¼ˆéœ€è¦æ£€æŸ¥çš„æ–‡ä»¶ï¼‰
        4. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
        """)
        st.markdown("â„¹ï¸ æç¤ºï¼šå¤§æ–‡ä»¶åˆ†æå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…")

    # æ–‡ä»¶ä¸Šä¼ åŒºä¼˜åŒ–
    st.subheader("ğŸ“‚ æ–‡ä»¶ä¸Šä¼ åŒº")
    
    # åŸºå‡†æ–‡ä»¶ä¸Šä¼ 
    st.markdown('<div class="file-selector"><span class="benchmark-label">åŸºå‡†æ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰ï¼š</span>é€‰æ‹©ä½œä¸ºåˆè§„æ€§åˆ¤æ–­ä¾æ®çš„æ–‡ä»¶</div>', unsafe_allow_html=True)
    bench_file = st.file_uploader(
        "ä¸Šä¼ åŸºå‡†æ–‡ä»¶ï¼ˆä»…æ”¯æŒPDFï¼‰",
        type=["pdf"],
        key="benchmark",
        accept_multiple_files=False,
        help="ä¾‹å¦‚ï¼šè¡Œä¸šæ ‡å‡†ã€å…¬å¸è§„å®šã€åˆåŒæ¨¡æ¿ç­‰"
    )

    # ç›®æ ‡æ–‡ä»¶ä¸Šä¼ 
    st.markdown('<div class="file-selector"><span class="target-label">ç›®æ ‡æ–‡ä»¶ï¼ˆå¯å¤šä¸ªï¼‰ï¼š</span>éœ€è¦è¿›è¡Œåˆè§„æ€§æ£€æŸ¥çš„æ–‡ä»¶</div>', unsafe_allow_html=True)
    target_files = st.file_uploader(
        "ä¸Šä¼ ç›®æ ‡æ–‡ä»¶ï¼ˆä»…æ”¯æŒPDFï¼‰",
        type=["pdf"],
        key="targets",
        accept_multiple_files=True,
        help="ä¾‹å¦‚ï¼šå¾…å®¡æ ¸çš„åˆåŒã€åè®®ã€è§„ç« åˆ¶åº¦ç­‰"
    )

    # åˆ†ææŒ‰é’®ï¼ˆå¢åŠ ç¡®è®¤æœºåˆ¶ï¼‰
    if st.button("å¼€å§‹1å¯¹å¤šåˆè§„æ€§åˆ†æ", type="primary"):
        if not bench_file:
            st.error("è¯·å…ˆä¸Šä¼ åŸºå‡†æ–‡ä»¶")
            return
        if not target_files:
            st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªç›®æ ‡æ–‡ä»¶")
            return
        if not qwen_api_key:
            st.error("è¯·è¾“å…¥Qwen APIå¯†é’¥")
            return

        # åŸºå‡†æ–‡ä»¶å¤„ç†
        with st.spinner("æ­£åœ¨è§£æåŸºå‡†æ–‡ä»¶..."):
            bench_text = extract_text_from_pdf(bench_file)
            if not bench_text:
                st.error("æ— æ³•æå–åŸºå‡†æ–‡ä»¶æ–‡æœ¬ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æœ‰æ•ˆæ€§")
                return

        # æ˜¾ç¤ºåˆ†æç»“æœ
        show_multi_target_analysis(
            bench_text, 
            target_files, 
            bench_file.name, 
            qwen_api_key,
            model_choice
        )

    # é¡µè„šä¿¡æ¯
    st.divider()
    st.markdown("""
    <div style="text-align:center; color:#666; margin-top:20px;">
        ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·ï¼ˆ1å¯¹å¤šç‰ˆï¼‰ | åŸºäºQwenå¤§æ¨¡å‹
        <br>æ³¨æ„ï¼šæœ¬å·¥å…·ä»…æä¾›è¾…åŠ©åˆ†æï¼Œä¸æ„æˆæ³•å¾‹æ„è§
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
